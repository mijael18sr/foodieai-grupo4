# ğŸ“Š MÃ©tricas del Modelo de AnÃ¡lisis de Sentimientos

## ğŸ¯ Rendimiento Actual del Modelo

| MÃ©trica | Valor | Estado |
|---------|-------|---------|
| **PrecisiÃ³n General** | **84.4%** | âœ… Excelente |
| **PrecisiÃ³n Macro** | **60.8%** | âš ï¸ Mejorable |
| **PrecisiÃ³n Weighted** | **86.1%** | âœ… Excelente |
| **Recall Macro** | **67.8%** | âš ï¸ Mejorable |
| **Recall Weighted** | **84.4%** | âœ… Excelente |
| **F1-Score Macro** | **62.5%** | âš ï¸ Mejorable |
| **F1-Score Weighted** | **84.6%** | âœ… Excelente |
| **Cohen's Kappa** | **0.561** | âœ… Bueno |
| **Matthews Correlation** | **0.569** | âœ… Bueno |

---

## ğŸ“š DefiniciÃ³n y CÃ¡lculo de MÃ©tricas

### ğŸ¯ **Accuracy (PrecisiÃ³n General)**
**Valor:** 84.4%

**DefiniciÃ³n:** Porcentaje de predicciones correctas sobre el total de predicciones.

**FÃ³rmula:**
```
Accuracy = (VP + VN) / (VP + VN + FP + FN)
```

**InterpretaciÃ³n:** De cada 100 comentarios analizados, el modelo clasifica correctamente 84.

---

### âš–ï¸ **Precision (PrecisiÃ³n)**

#### **Precision Macro: 60.8%**
**DefiniciÃ³n:** Promedio simple de la precisiÃ³n de cada clase.

**CÃ¡lculo desde mÃ©tricas por clase:**
```
Precision Macro = (Precision_Positivo + Precision_Neutro + Precision_Negativo) / 3
Precision Macro = (95.8% + 34.7% + 51.7%) / 3 = 60.8%
```

#### **Precision Weighted: 86.1%**
**DefiniciÃ³n:** Promedio ponderado por el nÃºmero de muestras de cada clase.

**FÃ³rmula:**
```
Precision Weighted = Î£(Precision_i Ã— Support_i) / Total_Samples
```

**InterpretaciÃ³n:** La precisiÃ³n macro baja indica que las clases minoritarias (neutro/negativo) tienen menor precisiÃ³n.

---

### ğŸ” **Recall (Exhaustividad)**

#### **Recall Macro: 67.8%**
**DefiniciÃ³n:** Promedio simple del recall de cada clase.

**CÃ¡lculo desde mÃ©tricas por clase:**
```
Recall Macro = (Recall_Positivo + Recall_Neutro + Recall_Negativo) / 3
Recall Macro = (90.1% + 25.8% + 87.5%) / 3 = 67.8%
```

#### **Recall Weighted: 84.4%**
**DefiniciÃ³n:** Promedio ponderado del recall por clase.

**InterpretaciÃ³n:** El modelo encuentra aproximadamente 2/3 de los casos reales de cada sentimiento.

---

### ğŸ² **F1-Score (Media ArmÃ³nica)**

#### **F1-Score Macro: 62.5%**
**DefiniciÃ³n:** Media armÃ³nica entre precisiÃ³n y recall, promediada por clase.

**FÃ³rmula por clase:**
```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
F1 Macro = (F1_Positivo + F1_Neutro + F1_Negativo) / 3
```

#### **F1-Score Weighted: 84.6%**
**DefiniciÃ³n:** F1-Score ponderado por el soporte de cada clase.

---

### ğŸ¤ **Cohen's Kappa: 0.561**
**DefiniciÃ³n:** Mide la concordancia entre clasificador y realidad, ajustado por el azar.

**InterpretaciÃ³n:**
- **0.0 - 0.20:** Concordancia pobre
- **0.21 - 0.40:** Concordancia dÃ©bil  
- **0.41 - 0.60:** Concordancia moderada âœ… (Nuestro caso)
- **0.61 - 0.80:** Concordancia buena
- **0.81 - 1.00:** Concordancia casi perfecta

**Equivalente a RÂ² para clasificaciÃ³n.**

---

### ğŸ“Š **Matthews Correlation Coefficient: 0.569**
**DefiniciÃ³n:** Coeficiente de correlaciÃ³n entre predicciones y valores reales.

**InterpretaciÃ³n:**
- **-1:** Predicciones completamente errÃ³neas
- **0:** Predicciones aleatorias
- **+1:** Predicciones perfectas
- **0.569:** CorrelaciÃ³n moderada-alta âœ…

---

## ğŸ“ˆ MÃ©tricas por Clase de Sentimiento

### ğŸ˜Š **Sentimientos Positivos**
| MÃ©trica | Valor | InterpretaciÃ³n |
|---------|-------|----------------|
| **Precision** | **95.8%** | âœ… Excelente: 96 de cada 100 predicciones "positivo" son correctas |
| **Recall** | **90.1%** | âœ… Excelente: Encuentra 90 de cada 100 comentarios positivos reales |
| **F1-Score** | **92.9%** | âœ… Excelente: Balance Ã³ptimo entre precisiÃ³n y recall |
| **Support** | **32,475** | ğŸ“Š Clase mayoritaria (81% del dataset) |

### ğŸ˜ **Sentimientos Neutros**
| MÃ©trica | Valor | InterpretaciÃ³n |
|---------|-------|----------------|
| **Precision** | **34.7%** | âš ï¸ Baja: Solo 35 de cada 100 predicciones "neutro" son correctas |
| **Recall** | **25.8%** | âš ï¸ Baja: Solo encuentra 26 de cada 100 comentarios neutros reales |
| **F1-Score** | **29.6%** | âŒ Deficiente: Necesita mejora urgente |
| **Support** | **3,429** | ğŸ“Š Clase minoritaria (8.5% del dataset) |

### ğŸ˜ **Sentimientos Negativos**
| MÃ©trica | Valor | InterpretaciÃ³n |
|---------|-------|----------------|
| **Precision** | **51.7%** | âš ï¸ Moderada: 52 de cada 100 predicciones "negativo" son correctas |
| **Recall** | **87.5%** | âœ… Excelente: Encuentra 88 de cada 100 comentarios negativos reales |
| **F1-Score** | **65.0%** | âš ï¸ Aceptable: Balance moderado |
| **Support** | **4,061** | ğŸ“Š Clase minoritaria (10.1% del dataset) |

---

## ğŸ¯ AnÃ¡lisis de Rendimiento

### âœ… **Fortalezas del Modelo**
1. **Excelente precisiÃ³n general (84.4%)** - Muy confiable para uso en producciÃ³n
2. **DetecciÃ³n de sentimientos positivos casi perfecta** (95.8% precisiÃ³n)
3. **Alta capacidad de encontrar comentarios negativos** (87.5% recall)
4. **MÃ©tricas ponderadas sÃ³lidas** - Buen rendimiento en la distribuciÃ³n real de datos

### âš ï¸ **Ãreas de Mejora**
1. **Sentimientos neutros muy problemÃ¡ticos** (29.6% F1-Score)
2. **Desbalance significativo de clases** (81% positivos vs 8.5% neutros)
3. **PrecisiÃ³n macro baja** (60.8%) indica problemas con clases minoritarias

### ğŸ¯ **EvaluaciÃ³n General**
**BUENO** - Modelo funcional para producciÃ³n con oportunidades claras de mejora.

---

## ğŸ”§ Recomendaciones para Mejora

### ğŸ¯ **Prioridad Alta**
1. **Balancear dataset:** Aumentar muestras de comentarios neutros y negativos
2. **Mejorar detecciÃ³n de neutros:** TÃ©cnicas de oversampling (SMOTE) o data augmentation
3. **Optimizar hiperparÃ¡metros:** GridSearchCV para Complement Naive Bayes

### ğŸ“Š **Metas Objetivo**
| MÃ©trica Actual | Valor Actual | Meta Objetivo | Mejora Necesaria |
|----------------|--------------|---------------|------------------|
| **Precision Macro** | 60.8% | **70-75%** | +10-15% |
| **Recall Macro** | 67.8% | **70-75%** | +3-8% |
| **F1-Score Macro** | 62.5% | **72-78%** | +10-15% |
| **F1 Neutros** | 29.6% | **50-60%** | +20-30% |

### ğŸš€ **Plan de Mejora**
1. **Semana 1:** Recolectar 2-3K comentarios neutros balanceados
2. **Semana 2:** Implementar tÃ©cnicas de data augmentation
3. **Semana 3:** Re-entrenar modelo con dataset balanceado
4. **Semana 4:** A/B testing modelo mejorado vs actual

---

## ğŸ› ï¸ ImplementaciÃ³n TÃ©cnica

### ğŸ“ **UbicaciÃ³n del CÃ³digo**
- **Modelo:** `backend/src/ml/models/sentiment_model.py`
- **API MÃ©tricas:** `backend/src/presentation/api/routes/sentiment.py`
- **Frontend:** `frontend/src/components/Sentiment/SentimentPanel.tsx`

### ğŸ”Œ **Endpoint de MÃ©tricas**
```bash
GET /api/v1/sentiment/model/metrics
```

### ğŸ“Š **Estructura de Respuesta**
```json
{
  "accuracy": 0.844,
  "precision_macro": 0.608,
  "precision_weighted": 0.861,
  "recall_macro": 0.678,
  "recall_weighted": 0.844,
  "f1_macro": 0.625,
  "f1_weighted": 0.846,
  "cohen_kappa": 0.561,
  "matthews_corrcoef": 0.569,
  "per_class_metrics": {
    "positivo": {
      "precision": 0.958,
      "recall": 0.901,
      "f1_score": 0.929,
      "support": 32475
    },
    "neutro": {
      "precision": 0.347,
      "recall": 0.258,
      "f1_score": 0.296,
      "support": 3429
    },
    "negativo": {
      "precision": 0.517,
      "recall": 0.875,
      "f1_score": 0.650,
      "support": 4061
    }
  }
}
```

---

## ğŸ“ Historial de Cambios

### ğŸ“… **2025-10-24**
- âœ… **Corregido:** Precision Macro y Recall Macro mostraban 0.0%
- ğŸ”§ **Implementado:** CÃ¡lculo automÃ¡tico desde mÃ©tricas por clase
- ğŸ“Š **Resultado:** MÃ©tricas ahora se muestran correctamente en UI

### ğŸ“Š **Valores Corregidos**
| MÃ©trica | Antes | DespuÃ©s |
|---------|-------|---------|
| Precision Macro | 0.0% | **60.8%** |
| Recall Macro | 0.0% | **67.8%** |

---

*Documento generado el 24 de Octubre, 2025*  
*Modelo: SentimentAnalysisModel v2 - Complement Naive Bayes*  
*Dataset: Restaurant Reviews Lima (39,965 muestras de test)*