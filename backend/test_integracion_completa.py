"""
Test de Integraci√≥n Completa del Sistema de M√©tricas y Confiabilidad
Verifica que todos los componentes funcionan correctamente juntos.
"""

import sys
from pathlib import Path

# Agregar el directorio ra√≠z al path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_integracion_completa():
    """Probar integraci√≥n completa del sistema"""

    print("=" * 80)
    print("üß™ TEST DE INTEGRACI√ìN COMPLETA")
    print("=" * 80)

    errores = []
    warnings = []

    # TEST 1: Cargar Modelo
    print("\n1Ô∏è‚É£ TEST: Cargar Modelo de Sentimientos")
    try:
        from src.ml.models import SentimentAnalysisModel

        model = SentimentAnalysisModel()
        model_path = project_root / "data" / "models" / "sentiment_model.pkl"

        if not model_path.exists():
            errores.append("‚ùå Modelo no encontrado en: " + str(model_path))
        else:
            model.load(str(model_path))
            print(f"   ‚úÖ Modelo cargado correctamente")
            print(f"   üìä Vocabulario: {len(model.vectorizer.vocabulary_):,} t√©rminos")
    except Exception as e:
        errores.append(f"‚ùå Error cargando modelo: {e}")

    # TEST 2: Servicio de An√°lisis con Nivel de Confianza
    print("\n2Ô∏è‚É£ TEST: Servicio de An√°lisis con Nivel de Confianza")
    try:
        from src.application.services.sentiment_service import SentimentAnalysisService, get_confidence_level
        from src.infrastructure.container import get_review_repository, get_sentiment_model

        # Crear servicio
        review_repo = get_review_repository()
        sentiment_model = get_sentiment_model()
        service = SentimentAnalysisService(review_repo, sentiment_model)

        # Probar an√°lisis
        test_comment = "La comida estuvo deliciosa"
        result = service.analyze_comment(test_comment)

        # Verificar que contiene confidence_level
        if 'confidence_level' not in result:
            errores.append("‚ùå El servicio NO retorna 'confidence_level'")
        else:
            print(f"   ‚úÖ Servicio retorna 'confidence_level': {result['confidence_level']}")
            print(f"   üìù Comentario: \"{test_comment}\"")
            print(f"   üéØ Sentimiento: {result['sentiment']}")
            print(f"   üìä Confianza: {result['confidence']:.1%}")
            print(f"   üè∑Ô∏è  Nivel: {result['confidence_level']}")

        # Probar funci√≥n get_confidence_level
        nivel = get_confidence_level(0.95)
        if nivel != "MUY CONFIABLE":
            errores.append(f"‚ùå get_confidence_level(0.95) deber√≠a ser 'MUY CONFIABLE', es '{nivel}'")
        else:
            print(f"   ‚úÖ Funci√≥n get_confidence_level funciona correctamente")

    except Exception as e:
        errores.append(f"‚ùå Error en servicio: {e}")
        import traceback
        traceback.print_exc()

    # TEST 3: DTOs actualizados
    print("\n3Ô∏è‚É£ TEST: DTOs con Campo confidence_level")
    try:
        from src.application.dto.sentiment_dto import SentimentAnalysisResponseDTO

        # Crear DTO de prueba
        dto = SentimentAnalysisResponseDTO(
            comment="Test comment",
            sentiment="positivo",
            confidence=0.95,
            confidence_level="MUY CONFIABLE",
            probabilities={"positivo": 0.95, "neutro": 0.03, "negativo": 0.02}
        )

        if dto.confidence_level != "MUY CONFIABLE":
            errores.append("‚ùå DTO no almacena correctamente confidence_level")
        else:
            print(f"   ‚úÖ DTO funciona correctamente con confidence_level")
            print(f"   üì¶ DTO creado: {dto.sentiment} ({dto.confidence:.1%}) - {dto.confidence_level}")

    except Exception as e:
        errores.append(f"‚ùå Error en DTOs: {e}")
        import traceback
        traceback.print_exc()

    # TEST 4: Endpoint de API (simulaci√≥n)
    print("\n4Ô∏è‚É£ TEST: Integraci√≥n con Endpoint de API")
    try:
        from src.presentation.api.routes.sentiment import analyze_sentiment
        from src.application.dto.sentiment_dto import SentimentAnalysisRequestDTO
        import asyncio

        # Crear request
        request = SentimentAnalysisRequestDTO(comment="Excelente servicio")

        # Ejecutar endpoint (simulaci√≥n)
        async def test_endpoint():
            response = await analyze_sentiment(request)
            return response

        # Ejecutar
        response = asyncio.run(test_endpoint())

        if not hasattr(response, 'confidence_level'):
            warnings.append("‚ö†Ô∏è Respuesta API no incluye confidence_level en el objeto")
        else:
            print(f"   ‚úÖ Endpoint retorna confidence_level correctamente")
            print(f"   üåê API Response: {response.sentiment} - {response.confidence_level}")

    except Exception as e:
        # No es cr√≠tico si falla (puede ser por configuraci√≥n de FastAPI)
        warnings.append(f"‚ö†Ô∏è No se pudo probar endpoint completo: {e}")
        print(f"   ‚ö†Ô∏è Prueba de endpoint omitida (no cr√≠tico)")

    # TEST 5: Funci√≥n interpretar_confianza
    print("\n5Ô∏è‚É£ TEST: Funci√≥n interpretar_confianza")
    try:
        from optimizar_modelo_gastron√≥mico import interpretar_confianza

        # Probar diferentes niveles
        test_cases = [
            (0.95, "MUY CONFIABLE"),
            (0.85, "CONFIABLE"),
            (0.75, "MODERADO"),
            (0.65, "BAJA CONFIANZA"),
            (0.50, "INDETERMINADO")
        ]

        all_ok = True
        for confidence, expected_status in test_cases:
            result = interpretar_confianza("positivo", confidence)
            if result['status'] != expected_status:
                errores.append(f"‚ùå interpretar_confianza({confidence}) esperaba '{expected_status}', obtuvo '{result['status']}'")
                all_ok = False

        if all_ok:
            print(f"   ‚úÖ Funci√≥n interpretar_confianza funciona para todos los umbrales")
            print(f"   üé® Umbrales verificados: ‚â•90%, ‚â•80%, ‚â•70%, ‚â•60%, <60%")

    except Exception as e:
        errores.append(f"‚ùå Error en interpretar_confianza: {e}")

    # TEST 6: Verificar Metadata del Modelo
    print("\n6Ô∏è‚É£ TEST: Metadata y M√©tricas del Modelo")
    try:
        if hasattr(model, 'metadata') and model.metadata:
            metadata = model.metadata

            print(f"   ‚úÖ Modelo tiene metadata")
            print(f"   üìã Tipo: {metadata.get('model_type', 'N/A')}")

            if 'test_metrics' in metadata:
                metrics = metadata['test_metrics']
                accuracy = metrics.get('accuracy', 0)
                kappa = metrics.get('cohen_kappa', 0)

                print(f"   üìä Accuracy: {accuracy:.1%}")
                print(f"   üìä Cohen's Kappa: {kappa:.4f}")

                if accuracy < 0.70:
                    warnings.append(f"‚ö†Ô∏è Accuracy es baja: {accuracy:.1%} (m√≠nimo recomendado: 75%)")

                if 'per_class' in metrics:
                    print(f"   üìä M√©tricas por clase disponibles: ‚úÖ")
                else:
                    warnings.append("‚ö†Ô∏è No hay m√©tricas por clase en metadata")
            else:
                warnings.append("‚ö†Ô∏è No hay m√©tricas de test en metadata")
        else:
            warnings.append("‚ö†Ô∏è Modelo no tiene metadata")
    except Exception as e:
        warnings.append(f"‚ö†Ô∏è Error leyendo metadata: {e}")

    # TEST 7: Prueba End-to-End
    print("\n7Ô∏è‚É£ TEST: Flujo End-to-End Completo")
    try:
        # Simular flujo completo: comentario ‚Üí servicio ‚Üí DTO ‚Üí respuesta
        comentarios_prueba = [
            ("La comida estuvo deliciosa", "positivo"),
            ("P√©simo servicio", "negativo"),
            ("Regular", "neutro")
        ]

        print("   üîÑ Probando flujo completo para 3 comentarios...")

        for comentario, sentimiento_esperado in comentarios_prueba:
            result = service.analyze_comment(comentario)

            # Verificar campos obligatorios
            required_fields = ['comment', 'sentiment', 'confidence', 'confidence_level', 'probabilities']
            missing_fields = [f for f in required_fields if f not in result]

            if missing_fields:
                errores.append(f"‚ùå Faltan campos en resultado: {missing_fields}")

            # Crear DTO
            dto = SentimentAnalysisResponseDTO(**result)

            print(f"   ‚úÖ \"{comentario[:30]}...\" ‚Üí {dto.sentiment} ({dto.confidence:.0%}) - {dto.confidence_level}")

    except Exception as e:
        errores.append(f"‚ùå Error en flujo end-to-end: {e}")
        import traceback
        traceback.print_exc()

    # RESUMEN FINAL
    print("\n" + "=" * 80)
    print("üìã RESUMEN DE PRUEBAS")
    print("=" * 80)

    total_tests = 7
    tests_passed = total_tests - len(errores)

    print(f"\n‚úÖ Tests Exitosos: {tests_passed}/{total_tests}")

    if errores:
        print(f"\n‚ùå ERRORES CR√çTICOS ({len(errores)}):")
        for error in errores:
            print(f"   {error}")

    if warnings:
        print(f"\n‚ö†Ô∏è ADVERTENCIAS ({len(warnings)}):")
        for warning in warnings:
            print(f"   {warning}")

    if not errores:
        print("\n" + "=" * 80)
        print("üéâ ¬°TODOS LOS TESTS PASARON EXITOSAMENTE!")
        print("=" * 80)
        print("\n‚úÖ El sistema est√° listo para usar con:")
        print("   ‚Ä¢ An√°lisis de sentimientos funcionando")
        print("   ‚Ä¢ Niveles de confiabilidad implementados")
        print("   ‚Ä¢ DTOs actualizados con confidence_level")
        print("   ‚Ä¢ Servicio retornando informaci√≥n completa")
        print("   ‚Ä¢ API lista para devolver niveles de confianza")
        print("\nüöÄ Puedes iniciar el servidor con: python start_server.py")
    else:
        print("\n" + "=" * 80)
        print("‚ö†Ô∏è HAY PROBLEMAS QUE RESOLVER")
        print("=" * 80)
        return False

    return True

if __name__ == "__main__":
    success = test_integracion_completa()
    sys.exit(0 if success else 1)

