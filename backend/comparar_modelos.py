"""
Comparaci√≥n de Modelos: Original vs Gastron√≥mico Optimizado
Muestra las m√©tricas exactas de ambos modelos
"""
import sys
from pathlib import Path

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

print("=" * 80)
print("üìä COMPARACI√ìN DE MODELOS DE SENTIMIENTOS")
print("=" * 80)

try:
    from src.ml.models import SentimentAnalysisModel

    modelos = [
        ("sentiment_model.pkl", "MODELO ACTUAL EN USO"),
        ("sentiment_model_gastro_optimized.pkl", "MODELO GASTRON√ìMICO OPTIMIZADO")
    ]

    resultados = {}

    for modelo_file, nombre in modelos:
        print(f"\n{'=' * 80}")
        print(f"üîç {nombre}")
        print(f"    Archivo: {modelo_file}")
        print("=" * 80)

        model_path = project_root / "data" / "models" / modelo_file

        if not model_path.exists():
            print(f"   ‚ùå No encontrado")
            continue

        try:
            model = SentimentAnalysisModel()
            model.load(str(model_path))
            print(f"   ‚úÖ Cargado correctamente")

            # Informaci√≥n b√°sica
            if hasattr(model, 'metadata') and model.metadata:
                metadata = model.metadata

                print(f"\n   üìã INFORMACI√ìN B√ÅSICA:")
                print(f"      Tipo: {metadata.get('model_type', 'N/A')}")
                print(f"      Vocabulario: {metadata.get('vocab_size', 0):,} t√©rminos")
                print(f"      Muestras: {metadata.get('n_samples', 0):,}")

                # M√©tricas de test
                if 'test_metrics' in metadata:
                    metrics = metadata['test_metrics']

                    accuracy = metrics.get('accuracy', 0)
                    kappa = metrics.get('cohen_kappa', 0)
                    f1_weighted = metrics.get('f1_weighted', 0)
                    f1_macro = metrics.get('f1_macro', 0)

                    print(f"\n   üéØ M√âTRICAS PRINCIPALES:")
                    print(f"      Accuracy:            {accuracy:.4f}  ({accuracy*100:.2f}%)")
                    print(f"      Cohen's Kappa:       {kappa:.4f}")
                    print(f"      F1-Score (weighted): {f1_weighted:.4f}  ({f1_weighted*100:.2f}%)")
                    print(f"      F1-Score (macro):    {f1_macro:.4f}  ({f1_macro*100:.2f}%)")

                    # Guardar para comparaci√≥n
                    resultados[nombre] = {
                        'accuracy': accuracy,
                        'kappa': kappa,
                        'f1_weighted': f1_weighted,
                        'f1_macro': f1_macro
                    }

                    # M√©tricas por clase
                    if 'per_class' in metrics:
                        print(f"\n   üìä M√âTRICAS POR CLASE:")

                        for clase in ['positivo', 'neutro', 'negativo']:
                            if clase in metrics['per_class']:
                                cm = metrics['per_class'][clase]
                                print(f"\n      {clase.upper()}:")
                                print(f"         Precision: {cm['precision']:.4f} ({cm['precision']*100:.1f}%)")
                                print(f"         Recall:    {cm['recall']:.4f} ({cm['recall']*100:.1f}%)")
                                print(f"         F1-Score:  {cm['f1-score']:.4f} ({cm['f1-score']*100:.1f}%)")
                                print(f"         Support:   {cm['support']} muestras")
                else:
                    print(f"\n   ‚ö†Ô∏è Sin m√©tricas de test guardadas")
            else:
                print(f"\n   ‚ö†Ô∏è Sin metadata")

        except Exception as e:
            print(f"   ‚ùå Error cargando: {e}")

    # COMPARACI√ìN DIRECTA
    if len(resultados) == 2:
        print(f"\n{'=' * 80}")
        print("üîÑ COMPARACI√ìN DIRECTA")
        print("=" * 80)

        modelo1_nombre, modelo2_nombre = list(resultados.keys())
        modelo1 = resultados[modelo1_nombre]
        modelo2 = resultados[modelo2_nombre]

        print(f"\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
        print(f"‚îÇ M√©trica                ‚îÇ Modelo Actual    ‚îÇ Modelo Optimizado‚îÇ Diferencia  ‚îÇ")
        print(f"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")

        metrics_compare = [
            ('Accuracy', 'accuracy'),
            ("Cohen's Kappa", 'kappa'),
            ('F1-Score (weighted)', 'f1_weighted'),
            ('F1-Score (macro)', 'f1_macro')
        ]

        for label, key in metrics_compare:
            val1 = modelo1[key] * 100
            val2 = modelo2[key] * 100
            diff = val2 - val1
            diff_str = f"+{diff:.2f}%" if diff > 0 else f"{diff:.2f}%"

            print(f"‚îÇ {label:22s} ‚îÇ {val1:15.2f}% ‚îÇ {val2:15.2f}% ‚îÇ {diff_str:>11s} ‚îÇ")

        print(f"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")

        # RECOMENDACI√ìN
        print(f"\n{'=' * 80}")
        print("üí° RECOMENDACI√ìN")
        print("=" * 80)

        acc_actual = modelo1['accuracy']
        acc_optimizado = modelo2['accuracy']

        if acc_optimizado > acc_actual + 0.02:  # Mejora de +2%
            print(f"\n‚úÖ USAR MODELO GASTRON√ìMICO OPTIMIZADO")
            print(f"   ‚Ä¢ Accuracy: {acc_optimizado*100:.2f}% (mejora de {(acc_optimizado-acc_actual)*100:.2f}%)")
            print(f"   ‚Ä¢ Mejor rendimiento general")
            print(f"\nüîß Para activar, ejecuta:")
            print(f"   copy data\\models\\sentiment_model_gastro_optimized.pkl data\\models\\sentiment_model.pkl")
        elif acc_actual > acc_optimizado + 0.02:
            print(f"\n‚úÖ MANTENER MODELO ACTUAL")
            print(f"   ‚Ä¢ Accuracy: {acc_actual*100:.2f}% (mejor que optimizado)")
            print(f"   ‚Ä¢ El modelo actual es superior")
        else:
            print(f"\nüü° MODELOS SIMILARES")
            print(f"   ‚Ä¢ Diferencia: {abs(acc_optimizado-acc_actual)*100:.2f}%")
            print(f"   ‚Ä¢ Considera A/B testing")
            print(f"   ‚Ä¢ Modelo Actual:     {acc_actual*100:.2f}%")
            print(f"   ‚Ä¢ Modelo Optimizado: {acc_optimizado*100:.2f}%")

    # PRUEBA CON EJEMPLOS REALES
    print(f"\n{'=' * 80}")
    print("üß™ PRUEBA CON EJEMPLOS REALES")
    print("=" * 80)

    ejemplos = [
        "La comida estuvo deliciosa y el servicio excelente",
        "Se atienden todos los domingos",
        "P√©simo servicio, muy lento",
        "Regular, nada especial"
    ]

    for modelo_file, nombre in modelos:
        model_path = project_root / "data" / "models" / modelo_file
        if model_path.exists():
            print(f"\n{'‚îÄ' * 80}")
            print(f"üîç {nombre}")
            print("‚îÄ" * 80)

            model = SentimentAnalysisModel()
            model.load(str(model_path))

            for ejemplo in ejemplos:
                result = model.predict_single(ejemplo)
                sentiment = result['sentiment'].upper()
                confidence = result['confidence']

                # Determinar nivel
                if confidence >= 0.90:
                    nivel = "MUY CONFIABLE ‚úì‚úì"
                elif confidence >= 0.80:
                    nivel = "CONFIABLE ‚úì"
                elif confidence >= 0.70:
                    nivel = "MODERADO ‚ö†"
                elif confidence >= 0.60:
                    nivel = "BAJA CONFIANZA ?"
                else:
                    nivel = "INDETERMINADO ‚úó"

                print(f"\n   üìù \"{ejemplo}\"")
                print(f"      ‚Üí {sentiment} ({confidence:.1%}) - {nivel}")

    print(f"\n{'=' * 80}")
    print("‚úÖ COMPARACI√ìN COMPLETADA")
    print("=" * 80)

except Exception as e:
    print(f"\n‚ùå ERROR: {e}")
    import traceback
    traceback.print_exc()

input("\nPresiona ENTER para salir...")

